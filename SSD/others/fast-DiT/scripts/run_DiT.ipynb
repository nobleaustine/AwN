{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "355UKMUQJxFd"
   },
   "source": [
    "# Scalable Diffusion Models with Transformer (DiT)\n",
    "\n",
    "This notebook samples from pre-trained DiT models. DiTs are class-conditional latent diffusion models trained on ImageNet that use transformers in place of U-Nets as the DDPM backbone. DiT outperforms all prior diffusion models on the ImageNet benchmarks.\n",
    "\n",
    "[Project Page](https://www.wpeebles.com/DiT) | [HuggingFace Space](https://huggingface.co/spaces/wpeebles/DiT) | [Paper](http://arxiv.org/abs/2212.09748) | [GitHub](github.com/facebookresearch/DiT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJlgLkSaKn7u"
   },
   "source": [
    "# 1. Setup\n",
    "\n",
    "We recommend using GPUs (Runtime > Change runtime type > Hardware accelerator > GPU). Run this cell to clone the DiT GitHub repo and setup PyTorch. You only have to run this once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'DiT'...\n",
      "remote: Enumerating objects: 102, done.\u001b[K\n",
      "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
      "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
      "remote: Total 102 (delta 55), reused 33 (delta 33), pack-reused 23\u001b[K\n",
      "Receiving objects: 100% (102/102), 6.37 MiB | 10.69 MiB/s, done.\n",
      "Resolving deltas: 100% (55/55), done.\n",
      "Requirement already satisfied: diffusers in /cluster/home/austinen/anaconda3/envs/DiT/lib/python3.8/site-packages (0.27.2)\n",
      "Requirement already satisfied: timm in /cluster/home/austinen/anaconda3/envs/DiT/lib/python3.8/site-packages (0.9.16)\n",
      "Collecting timm\n",
      "  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /cluster/home/austinen/.local/lib/python3.8/site-packages (from diffusers) (1.6.1)\n",
      "Requirement already satisfied: filelock in /cluster/home/austinen/anaconda3/envs/DiT/lib/python3.8/site-packages (from diffusers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.2 in /cluster/home/austinen/anaconda3/envs/DiT/lib/python3.8/site-packages (from diffusers) (0.22.2)\n",
      "Requirement already satisfied: numpy in /cluster/home/austinen/.local/lib/python3.8/site-packages (from diffusers) (1.24.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /cluster/home/austinen/anaconda3/envs/DiT/lib/python3.8/site-packages (from diffusers) (2024.4.28)\n",
      "Requirement already satisfied: requests in /cluster/home/austinen/.local/lib/python3.8/site-packages (from diffusers) (2.23.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /cluster/home/austinen/anaconda3/envs/DiT/lib/python3.8/site-packages (from diffusers) (0.4.3)\n",
      "Requirement already satisfied: Pillow in /cluster/home/austinen/.local/lib/python3.8/site-packages (from diffusers) (7.1.2)\n",
      "Requirement already satisfied: torch in /cluster/home/austinen/.local/lib/python3.8/site-packages (from timm) (1.13.1+cu117)\n",
      "Requirement already satisfied: torchvision in /cluster/home/austinen/.local/lib/python3.8/site-packages (from timm) (0.14.1+cu117)\n",
      "Requirement already satisfied: pyyaml in /cluster/home/austinen/.local/lib/python3.8/site-packages (from timm) (5.3.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /cluster/home/austinen/anaconda3/envs/DiT/lib/python3.8/site-packages (from huggingface-hub>=0.20.2->diffusers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /cluster/home/austinen/anaconda3/envs/DiT/lib/python3.8/site-packages (from huggingface-hub>=0.20.2->diffusers) (24.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /cluster/home/austinen/.local/lib/python3.8/site-packages (from huggingface-hub>=0.20.2->diffusers) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /cluster/home/austinen/.local/lib/python3.8/site-packages (from huggingface-hub>=0.20.2->diffusers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /cluster/home/austinen/.local/lib/python3.8/site-packages (from importlib-metadata->diffusers) (3.1.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /cluster/home/austinen/anaconda3/envs/DiT/lib/python3.8/site-packages (from requests->diffusers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /cluster/home/austinen/.local/lib/python3.8/site-packages (from requests->diffusers) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /cluster/home/austinen/.local/lib/python3.8/site-packages (from requests->diffusers) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cluster/home/austinen/.local/lib/python3.8/site-packages (from requests->diffusers) (2020.4.5.2)\n",
      "Downloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: timm\n",
      "  Attempting uninstall: timm\n",
      "    Found existing installation: timm 0.9.16\n",
      "    Uninstalling timm-0.9.16:\n",
      "      Successfully uninstalled timm-0.9.16\n",
      "Successfully installed timm-1.0.3\n",
      "GPU not found. Using CPU instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/austinen/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 805: MPS client failed to connect to the MPS control daemon or the MPS server (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/DiT.git\n",
    "import DiT, os\n",
    "os.chdir('DiT')\n",
    "os.environ['PYTHONPATH'] = '/env/python:/content/DiT'\n",
    "!pip install diffusers timm --upgrade\n",
    "# DiT imports:\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "from diffusion import create_diffusion\n",
    "from diffusers.models import AutoencoderKL\n",
    "from download import find_model\n",
    "from models import DiT_XL_2\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "torch.set_grad_enabled(False)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cpu\":\n",
    "    print(\"GPU not found. Using CPU instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXpziRkoOvV9"
   },
   "source": [
    "# Download DiT-XL/2 Models\n",
    "\n",
    "You can choose between a 512x512 model and a 256x256 model. You can swap-out the LDM VAE, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EWG-WNimO59K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://dl.fbaipublicfiles.com/DiT/models/DiT-XL-2-256x256.pt to pretrained_models/DiT-XL-2-256x256.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d9c2d2ca20461090df920d058a005b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2700611775 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_size = 256 #@param [256, 512]\n",
    "vae_model = \"stabilityai/sd-vae-ft-ema\" #@param [\"stabilityai/sd-vae-ft-mse\", \"stabilityai/sd-vae-ft-ema\"]\n",
    "latent_size = int(image_size) // 8\n",
    "# Load model:\n",
    "model = DiT_XL_2(input_size=latent_size).to(device)\n",
    "state_dict = find_model(f\"DiT-XL-2-{image_size}x{image_size}.pt\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval() # important!\n",
    "vae = AutoencoderKL.from_pretrained(vae_model).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JTNyzNZKb9E"
   },
   "source": [
    "# 2. Sample from Pre-trained DiT Models\n",
    "\n",
    "You can customize several sampling options. For the full list of ImageNet classes, [check out this](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-Hw7B5h4Kk4p"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c84eea8c8e4c9ebeaf3b0007db20c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set user inputs:\n",
    "seed = 0 #@param {type:\"number\"}\n",
    "torch.manual_seed(seed)\n",
    "num_sampling_steps = 250 #@param {type:\"slider\", min:0, max:1000, step:1}\n",
    "cfg_scale = 4 #@param {type:\"slider\", min:1, max:10, step:0.1}\n",
    "class_labels = 207, 360, 387, 974, 88, 979, 417, 279 #@param {type:\"raw\"}\n",
    "samples_per_row = 4 #@param {type:\"number\"}\n",
    "\n",
    "# Create diffusion object:\n",
    "diffusion = create_diffusion(str(num_sampling_steps))\n",
    "\n",
    "# Create sampling noise:\n",
    "n = len(class_labels)\n",
    "z = torch.randn(n, 4, latent_size, latent_size, device=device)\n",
    "y = torch.tensor(class_labels, device=device)\n",
    "\n",
    "# Setup classifier-free guidance:\n",
    "z = torch.cat([z, z], 0)\n",
    "y_null = torch.tensor([1000] * n, device=device)\n",
    "y = torch.cat([y, y_null], 0)\n",
    "model_kwargs = dict(y=y, cfg_scale=cfg_scale)\n",
    "\n",
    "# Sample images:\n",
    "samples = diffusion.p_sample_loop(\n",
    "    model.forward_with_cfg, z.shape, z, clip_denoised=False, \n",
    "    model_kwargs=model_kwargs, progress=True, device=device\n",
    ")\n",
    "samples, _ = samples.chunk(2, dim=0)  # Remove null class samples\n",
    "samples = vae.decode(samples / 0.18215).sample\n",
    "\n",
    "# Save and display images:\n",
    "save_image(samples, \"sample.png\", nrow=int(samples_per_row), \n",
    "           normalize=True, value_range=(-1, 1))\n",
    "samples = Image.open(\"sample.png\")\n",
    "display(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PYTORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5582, 0.8384, 0.8436, 0.2354],\n",
      "          [0.2947, 0.9504, 0.3292, 0.8884],\n",
      "          [0.1030, 0.4064, 0.5709, 0.3271]],\n",
      "\n",
      "         [[0.3816, 0.7789, 0.2523, 0.6280],\n",
      "          [0.1720, 0.6519, 0.8004, 0.7060],\n",
      "          [0.1095, 0.9498, 0.1172, 0.2554]]]])\n",
      "tensor([[[[0.4162, 0.3613, 0.4239, 0.2489],\n",
      "          [0.3198, 0.4041, 0.2534, 0.4783],\n",
      "          [0.2640, 0.2346, 0.3227, 0.2728]],\n",
      "\n",
      "         [[0.3887, 0.3261, 0.2775, 0.3610],\n",
      "          [0.3152, 0.2872, 0.4801, 0.3903],\n",
      "          [0.2961, 0.3868, 0.2424, 0.2487]]]])\n",
      "tensor([[[1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000]]])\n"
     ]
    }
   ],
   "source": [
    "a = th.rand(1,2,3,4)\n",
    "# print(a)\n",
    "# b = th.argmax(F.softmax(a,dim=2),axis=2)\n",
    "# print(b)\n",
    "print(a)\n",
    "k = F.softmax(a,dim=2)\n",
    "# k = th.sum(b,dim=2)\n",
    "print(k)\n",
    "k = th.sum(k,dim=2)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.3357, 0.0761, 0.1998],\n",
       "          [0.6062, 0.0993, 0.9665],\n",
       "          [0.9869, 0.7946, 0.7680],\n",
       "          [0.7404, 0.5994, 0.1234]],\n",
       " \n",
       "         [[0.7745, 0.2094, 0.2938],\n",
       "          [0.5635, 0.9947, 0.3598],\n",
       "          [0.3647, 0.1045, 0.3568],\n",
       "          [0.2566, 0.8713, 0.9351]]]),\n",
       " tensor([[[-0.1619,  1.4103, -0.6718],\n",
       "          [-1.4412, -0.5914,  1.9748],\n",
       "          [-0.0396, -0.1573,  0.8775],\n",
       "          [ 0.1963,  1.4566,  2.2303]],\n",
       " \n",
       "         [[ 1.8923,  0.1595,  0.4503],\n",
       "          [-0.0341, -0.5649,  0.4817],\n",
       "          [ 0.9184, -0.6458,  1.2508],\n",
       "          [ 0.0972, -0.6601, -1.7134]]]),\n",
       " tensor([[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]]),\n",
       " tensor([[[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]]]),\n",
       " tensor([[[6, 6, 6],\n",
       "          [6, 6, 6],\n",
       "          [6, 6, 6],\n",
       "          [6, 6, 6]],\n",
       " \n",
       "         [[6, 6, 6],\n",
       "          [6, 6, 6],\n",
       "          [6, 6, 6],\n",
       "          [6, 6, 6]]]),\n",
       " tensor([[[3., 3., 3.],\n",
       "          [3., 3., 3.],\n",
       "          [3., 3., 3.],\n",
       "          [3., 3., 3.]],\n",
       " \n",
       "         [[3., 3., 3.],\n",
       "          [3., 3., 3.],\n",
       "          [3., 3., 3.],\n",
       "          [3., 3., 3.]]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2\n",
    "T = 4\n",
    "D = 3\n",
    "t1 = th.rand(N,T,D)\n",
    "t2 = th.randn(N,T,D)\n",
    "t3 = th.zeros(N,T,D)\n",
    "t4 = th.ones(N,T,D)\n",
    "t5 = th.full((N,T,D),6)\n",
    "t6 = 3*t4\n",
    "t1,t2,t3,t4,t5,t6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.3357, 0.0761, 0.1998],\n",
       "          [0.6062, 0.0993, 0.9665],\n",
       "          [0.9869, 0.7946, 0.7680],\n",
       "          [0.7404, 0.5994, 0.1234]],\n",
       " \n",
       "         [[0.7745, 0.2094, 0.2938],\n",
       "          [0.5635, 0.9947, 0.3598],\n",
       "          [0.3647, 0.1045, 0.3568],\n",
       "          [0.2566, 0.8713, 0.9351]]]),\n",
       " torch.Size([2, 3]),\n",
       " tensor([[0.3357, 0.0761, 0.1998],\n",
       "         [0.7745, 0.2094, 0.2938]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1,t1[:,-4,:].shape,t1[:,-4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2622,  0.3692,  0.0302,  0.0108, -0.3587,  0.2882],\n",
       "        [ 0.1102,  0.2648, -0.1780, -0.0627, -0.3972, -0.3387],\n",
       "        [-0.3600, -0.2968, -0.0796, -0.0439,  0.1984,  0.2068],\n",
       "        [ 0.1410, -0.3960,  0.0128,  0.2042, -0.0569,  0.1763]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size = 6\n",
    "input_size = 4\n",
    "l = nn.Linear(6,4,bias=True)\n",
    "l.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.99653848 0.74497918 0.74118636 0.55491099]\n",
      "  [0.6008518  0.50982715 0.80114502 0.49731264]]\n",
      "\n",
      " [[0.1201585  0.5096922  0.25460918 0.82141725]\n",
      "  [0.09198959 0.21342022 0.55442237 0.70965507]]\n",
      "\n",
      " [[0.76007615 0.65889005 0.84394497 0.17147846]\n",
      "  [0.91701943 0.90906091 0.97572201 0.6849114 ]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99653848, 0.74497918, 0.74118636, 0.55491099, 0.6008518 ,\n",
       "       0.50982715, 0.80114502, 0.49731264, 0.1201585 , 0.5096922 ,\n",
       "       0.25460918, 0.82141725, 0.09198959, 0.21342022, 0.55442237,\n",
       "       0.70965507, 0.76007615, 0.65889005, 0.84394497, 0.17147846,\n",
       "       0.91701943, 0.90906091, 0.97572201, 0.6849114 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "b = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "c = np.concatenate([a,b],axis = 1)\n",
    "c.reshape(-1)\n",
    "d = np.random.rand(3,2,4)\n",
    "print(d)\n",
    "d = d.reshape(-1)\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['path1', 'path2', 'path3', 'path4', 'path5']\n",
      "['path1', 'path2', 'path3', 'path4', 'path5']\n",
      "['path4', 'path2', 'path3', 'path5', 'path1']\n",
      "['path1', 'path2', 'path3', 'path4', 'path5']\n",
      "['path4', 'path2', 'path3', 'path5', 'path1']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "data_paths = [\"path1\", \"path2\", \"path3\", \"path4\", \"path5\"]\n",
    "print(data_paths)\n",
    "random.seed(42)\n",
    "a = [k for k in data_paths]\n",
    "print(a)\n",
    "random.shuffle(a)\n",
    "print(a)\n",
    "b= [k for k in data_paths]\n",
    "print(b)\n",
    "random.seed(42)\n",
    "random.shuffle(b)\n",
    "print(b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 512, 512)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "a = np.random.rand(480,512,512)\n",
    "def pad_array(t):\n",
    "   if t.shape[0] != 640:\n",
    "    s = (640 - t.shape[0])//2\n",
    "    padding = ((s,s), (0, 0), (0, 0))\n",
    "    t = np.pad(t, padding, mode='constant', constant_values=0)\n",
    "   return t\n",
    "\n",
    "b = pad_array(a)\n",
    "b.shape"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
